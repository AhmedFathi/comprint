{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file was created by the Image Processing Research Group of University Federico II of Naples ('GRIP-UNINA')\n",
    "# and adapted by IDLab-MEDIA, Ghent University - imec, in collaboration with GRIP-UNINA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-15 15:02:18.177568: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-15 15:02:18.177598: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-15 15:02:18.177637: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks\n",
    "\n",
    "import splicebuster\n",
    "import splicebuster.main_blind_function\n",
    "import splicebuster.noiseprint.noiseprint_blind_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_folder = f\"/project_ghent/public/comprint\"\n",
    "main_folder = f\"/project_ghent/comprint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "def get_model(modelname, main_folder):\n",
    "    if modelname == \"full-jpg-ps-full\":\n",
    "        model = ks.models.load_model('%s/models/Comprint_Siamese_Full_jpg_ps_full' % main_folder)\n",
    "        print(\"Model %s loaded\" % modelname)\n",
    "    elif modelname == \"net\":\n",
    "        # For noiseprint, load different model depending on jpg QF\n",
    "        print(\"Don't load model %s because it's dependent on QF\" % modelname)\n",
    "        noiseprint_model_folder = f\"%s/models/noiseprint_nets\" % (main_folder)\n",
    "        model = \"%s/%s\" % (noiseprint_model_folder, modelname)\n",
    "        print(model)\n",
    "    else:\n",
    "        print(\"Model %s not found\" % modelname)\n",
    "        model = None\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnames = [\"full-jpg-ps-full\"] # Comprint\n",
    "modelnames = [\"net\"] # Noiseprint\n",
    "modelnames = [\"full-jpg-ps-full\", \"net\"] # Fusion of Comprint + Noiseprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model full-jpg-ps-full loaded\n",
      "Don't load model net because it's dependent on QF\n",
      "/project_ghent/comprint/models/noiseprint_nets/net\n",
      "Full modelname: _concat_full-jpg-ps-full_net\n"
     ]
    }
   ],
   "source": [
    "# Load model(s)\n",
    "models = []\n",
    "modelname_full = \"\"\n",
    "if len(modelnames) > 1:\n",
    "    modelname_full = \"_concat\"\n",
    "for modelname in modelnames:\n",
    "    model = get_model(modelname, main_folder)\n",
    "    models.append(model)\n",
    "    modelname_full = \"%s_%s\" % (modelname_full, modelname)\n",
    "    \n",
    "print(\"Full modelname: %s\" % modelname_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET INPUT FOLDERS\n",
    "main_folder_data = \"/project_ghent/public/comprint\"\n",
    "input_folder = \"%s/data/examples_input\" % main_folder_data\n",
    "output_folder = \"%s/data/examples_output\" % main_folder_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET INPUT\n",
    "# You can set another input file here\n",
    "input_filename = \"facehub-fake.png\"\n",
    "#input_filename = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert filenames to full paths for the output files\n",
    "def get_output_filenames(input_filename, input_folder, output_folder):\n",
    "    input_file = f\"%s/%s\" % (input_folder, input_filename)\n",
    "    output_filename = \"%s/%s%s\" % (input_filename, input_filename, modelname_full)\n",
    "\n",
    "    fingerprint_files = []\n",
    "    output_filename_base = \"%s/%s\" % (input_filename, input_filename)\n",
    "    output_file_base = f\"%s/%s\" % (output_folder, output_filename_base)\n",
    "    for modelname in modelnames:\n",
    "        fingerprint_file = f\"%s_%s_res.png\" % (output_file_base, modelname)\n",
    "        fingerprint_files.append(fingerprint_file)\n",
    "\n",
    "        # Build concatenated filename\n",
    "        output_filename = \"%s_%s\" % (output_filename, modelname)\n",
    "\n",
    "    output_file = f\"%s/%s\" % (output_folder, output_filename)\n",
    "    #output_file_npz = f\"%s.npz\" % (output_file)\n",
    "    heatmap_file = f\"%s_heatmap.png\" % (output_file)\n",
    "    return input_file, output_file, fingerprint_files, heatmap_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project_ghent/public/comprint/data/examples_input/facehub-fake.png\n",
      "/project_ghent/public/comprint/data/examples_output/facehub-fake.png/facehub-fake.png_concat_full-jpg-ps-full_net_full-jpg-ps-full_net\n",
      "['/project_ghent/public/comprint/data/examples_output/facehub-fake.png/facehub-fake.png_full-jpg-ps-full_res.png', '/project_ghent/public/comprint/data/examples_output/facehub-fake.png/facehub-fake.png_net_res.png']\n",
      "/project_ghent/public/comprint/data/examples_output/facehub-fake.png/facehub-fake.png_concat_full-jpg-ps-full_net_full-jpg-ps-full_net_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "input_file, output_file, fingerprint_files, heatmap_file = get_output_filenames(input_filename, input_folder, output_folder)\n",
    "\n",
    "print(input_file)\n",
    "print(output_file)\n",
    "print(fingerprint_files)\n",
    "print(heatmap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start detection on /project_ghent/public/comprint/data/examples_input/facehub-fake.png\n",
      "INFO:tensorflow:Restoring parameters from /project_ghent/comprint/models/noiseprint_nets/net_jpg101/model\n",
      " 312x696 small 101\n",
      "Heatmap saved to /project_ghent/public/comprint/data/examples_output/facehub-fake.png/facehub-fake.png_concat_full-jpg-ps-full_net_full-jpg-ps-full_net_heatmap.png\n",
      "Finished in 10.166313 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run fingerprint extraction and forgery localization algorithm\n",
    "print(\"Start detection on %s\" % input_file)\n",
    "t = time()\n",
    "splicebuster.main_blind_function.extract_heatmap_concat(input_file, output_file, models, fingerprint_files, heatmap_file)\n",
    "elapsed_time = time() - t\n",
    "print(f\"Finished in %f seconds\" % elapsed_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
